{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Univariate, Bivariate, and Multivariate Analysis\n",
        "## Genomics Sequence Classification Dataset\n",
        "\n",
        "This notebook performs comprehensive statistical analysis on genomics sequence data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import stats\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv('../../data/genomics_data.csv')\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature Engineering\n",
        "Extract features from DNA sequences for analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_sequence_features(sequences):\n",
        "    \"\"\"Extract features from DNA sequences\"\"\"\n",
        "    from collections import Counter\n",
        "    features = []\n",
        "    \n",
        "    for seq in sequences:\n",
        "        seq = str(seq).upper()\n",
        "        length = len(seq)\n",
        "        gc_content = (seq.count('G') + seq.count('C')) / length if length > 0 else 0\n",
        "        a_freq = seq.count('A') / length if length > 0 else 0\n",
        "        t_freq = seq.count('T') / length if length > 0 else 0\n",
        "        g_freq = seq.count('G') / length if length > 0 else 0\n",
        "        c_freq = seq.count('C') / length if length > 0 else 0\n",
        "        \n",
        "        # K-mer frequencies\n",
        "        kmer_2 = {}\n",
        "        for i in range(len(seq) - 1):\n",
        "            kmer = seq[i:i+2]\n",
        "            kmer_2[kmer] = kmer_2.get(kmer, 0) + 1\n",
        "        \n",
        "        total_kmers = sum(kmer_2.values()) if kmer_2 else 1\n",
        "        aa_freq = kmer_2.get('AA', 0) / total_kmers\n",
        "        at_freq = kmer_2.get('AT', 0) / total_kmers\n",
        "        \n",
        "        # Sequence entropy\n",
        "        counts = Counter(seq)\n",
        "        entropy = -sum((count/len(seq)) * np.log2(count/len(seq)) \n",
        "                      for count in counts.values() if count > 0)\n",
        "        \n",
        "        features.append({\n",
        "            'length': length, 'gc_content': gc_content,\n",
        "            'a_freq': a_freq, 't_freq': t_freq, 'g_freq': g_freq, 'c_freq': c_freq,\n",
        "            'aa_freq': aa_freq, 'at_freq': at_freq, 'entropy': entropy\n",
        "        })\n",
        "    \n",
        "    return pd.DataFrame(features)\n",
        "\n",
        "# Extract features\n",
        "feature_df = extract_sequence_features(df['Sequences'])\n",
        "df_features = pd.concat([df, feature_df], axis=1)\n",
        "print(\"Features extracted!\")\n",
        "df_features.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. UNIVARIATE ANALYSIS\n",
        "Analyzing individual variables in isolation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Univariate Analysis - Continuous Variables\n",
        "numeric_cols = ['length', 'gc_content', 'a_freq', 't_freq', 'g_freq', 'c_freq', 'entropy']\n",
        "\n",
        "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, col in enumerate(numeric_cols):\n",
        "    ax = axes[idx]\n",
        "    ax.hist(df_features[col], bins=30, alpha=0.7, edgecolor='black')\n",
        "    ax.set_title(f'Distribution of {col}', fontsize=12, fontweight='bold')\n",
        "    ax.set_xlabel(col)\n",
        "    ax.set_ylabel('Frequency')\n",
        "    ax.axvline(df_features[col].mean(), color='red', linestyle='--', label=f'Mean: {df_features[col].mean():.3f}')\n",
        "    ax.axvline(df_features[col].median(), color='green', linestyle='--', label=f'Median: {df_features[col].median():.3f}')\n",
        "    ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('../../results/univariate_continuous.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. BIVARIATE ANALYSIS\n",
        "Analyzing relationships between pairs of variables\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Bivariate Analysis - Correlation Matrix\n",
        "correlation_matrix = df_features[numeric_cols].corr()\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', \n",
        "            center=0, square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
        "plt.title('Correlation Matrix - Feature Relationships', fontsize=16, fontweight='bold', pad=20)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../../results/bivariate_correlation.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. MULTIVARIATE ANALYSIS\n",
        "Analyzing relationships among multiple variables simultaneously\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Multivariate Analysis - PCA\n",
        "X = df_features[numeric_cols].values\n",
        "y = df_features['Labels'].values\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=2)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Plot PCA\n",
        "plt.figure(figsize=(12, 8))\n",
        "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.6, edgecolors='black')\n",
        "plt.colorbar(scatter, label='Label')\n",
        "plt.xlabel(f'First Principal Component (Explained Variance: {pca.explained_variance_ratio_[0]:.2%})')\n",
        "plt.ylabel(f'Second Principal Component (Explained Variance: {pca.explained_variance_ratio_[1]:.2%})')\n",
        "plt.title('PCA - Multivariate Analysis', fontsize=16, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('../../results/multivariate_pca.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Total Explained Variance: {sum(pca.explained_variance_ratio_):.2%}\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
