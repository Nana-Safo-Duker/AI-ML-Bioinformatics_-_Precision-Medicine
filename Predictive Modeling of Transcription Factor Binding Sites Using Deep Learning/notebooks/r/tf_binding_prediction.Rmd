---
title: "Transcription Factor Binding Prediction in R"
author: "AI-ML Bioinformatics Team"
date: "2024"
output:
  html_document:
    toc: true
    toc_float: true
    code_folding: show
  pdf_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction

This notebook implements comprehensive analysis and prediction of transcription factor (TF) binding sites using multiple machine learning approaches in R.

## Objectives

1. Load and explore genomics data
2. Preprocess DNA sequences
3. Train multiple models (Random Forest, XGBoost, SVM, Neural Network, Logistic Regression)
4. Evaluate and compare model performance
5. Visualize results

## Dataset

- **Sequences**: DNA sequences (50 nucleotides)
- **Labels**: Binary labels (0 = no binding, 1 = TF binding)

## Load Libraries

```{r libraries}
suppressPackageStartupMessages({
  library(tidyverse)
  library(caret)
  library(randomForest)
  library(xgboost)
  library(e1071)
  library(neuralnet)
  library(pROC)
  library(ggplot2)
  library(reshape2)
  library(doParallel)
  library(gridExtra)
})

set.seed(42)
```

## Load and Explore Data

```{r load-data}
# Load data
data_path <- "../../data/genomics_data.csv"
df <- read.csv(data_path, stringsAsFactors = FALSE)

cat("Data shape:", nrow(df), "rows,", ncol(df), "columns\n")
cat("\nFirst few rows:\n")
head(df)

cat("\nLabel distribution:\n")
table(df$Labels)

cat("\nLabel distribution (%):\n")
prop.table(table(df$Labels)) * 100
```

## Data Preprocessing

```{r preprocessing}
# Source the main script functions
source("../../scripts/r/tf_binding_prediction.R")

# Load and preprocess data
data_list <- load_and_preprocess_data(data_path)
```

## Train Models

```{r train-models}
# Train all models
models <- list()
models$random_forest <- train_random_forest(data_list$X_train, data_list$y_train)
models$xgboost <- train_xgboost(data_list$X_train, data_list$y_train)
models$svm <- train_svm(data_list$X_train, data_list$y_train)
models$neural_network <- train_neural_network(data_list$train_data)
models$logistic <- train_logistic_regression(data_list$train_data)
```

## Evaluate Models

```{r evaluate-models}
# Evaluate all models
results <- list()
results$random_forest <- evaluate_model(models$random_forest, data_list$X_test, 
                                        data_list$y_test, "random_forest")
results$xgboost <- evaluate_model(models$xgboost, data_list$X_test, 
                                  data_list$y_test, "xgboost")
results$svm <- evaluate_model(models$svm, data_list$X_test, 
                              data_list$y_test, "svm")
results$neural_network <- evaluate_model(models$neural_network, data_list$X_test, 
                                         data_list$y_test, "neural_network")
results$logistic <- evaluate_model(models$logistic, data_list$X_test, 
                                   data_list$y_test, "logistic")
```

## Model Comparison

```{r model-comparison}
# Create comparison dataframe
results_summary <- data.frame(
  Model = names(results),
  Accuracy = sapply(results, function(x) x$accuracy),
  Precision = sapply(results, function(x) x$precision),
  Recall = sapply(results, function(x) x$recall),
  F1_Score = sapply(results, function(x) x$f1),
  ROC_AUC = sapply(results, function(x) x$roc_auc)
)

print(results_summary)
```

## Visualize Results

```{r visualize-results}
# Plot confusion matrices
plot_confusion_matrices(results)

# Plot ROC curves
plot_roc_curves(results)
```

## Save Models and Results

```{r save-results}
# Save models and results
save_models_and_results(models, results)
```

## Conclusions

This notebook demonstrated:
1. Data loading and exploration
2. Multiple model training (Random Forest, XGBoost, SVM, Neural Network, Logistic Regression)
3. Comprehensive model evaluation
4. Visualization of results
5. Model saving and comparison

The best performing model can be selected based on the evaluation metrics and used for predicting transcription factor binding sites in new DNA sequences.

